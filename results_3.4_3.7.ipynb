{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "from sklearn.ensemble import ExtraTreesRegressor, ExtraTreesClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from utils import bayescv, reg_scores, cls_scores, plot_permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',1000)\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "sns.set_theme(style='whitegrid')\n",
    "model_types = ['extratree', 'gradientboost']\n",
    "thres = 1.03\n",
    "n_iter = 30\n",
    "random_state = 42\n",
    "\n",
    "cls = model_types[0]\n",
    "zscore = False\n",
    "bayes = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BF2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_bf2_df = pd.read_csv('csv/BF2_R.csv')\n",
    "load_bf2_df['APOE'].replace({22.: '22', 23.: '23', 24.: '24', 33.: '33', 34.: '34', 44.: '44'}, inplace=True)\n",
    "if zscore:\n",
    "    load_bf1_df = pd.read_csv('csv/BF1_R_Z.csv')\n",
    "    load_bf1_df['APOE'].replace({22.: '22', 23.: '23', 24.: '24', 33.: '33', 34.: '34', 44.: '44'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptau217 = ['Plasma WashU %P-tau217',\n",
    "           'Plasma Lilly P-tau217',\n",
    "           'CSF Lilly P-tau217',\n",
    "           'CSF WashU P-tau217']\n",
    "\n",
    "common = ['CSF Aβ42/Aβ40',\n",
    "          'Age',\n",
    "          'APOE',\n",
    "          'ADAS',\n",
    "          'Education',\n",
    "          'Sex',\n",
    "          'Cognitive status',\n",
    "          'MMSE',\n",
    "          'CSF Abnormal Ratio',\n",
    "          'Diagnosis status',\n",
    "          'fnc_ber_com_composite']\n",
    "\n",
    "cd_drop = [ 'CSF Aβ42/Aβ40',\n",
    "                'Age',\n",
    "                'APOE',\n",
    "                'ADAS',\n",
    "                'Education',\n",
    "                'Sex',\n",
    "                'Cognitive status',\n",
    "                'MMSE',\n",
    "                'CSF Abnormal Ratio',\n",
    "                'Diagnosis status']\n",
    "\n",
    "name = ['BF2-P-MS','BF2-P-IA','BF2-C-IA','BF2-C-MS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptau217_index = 0\n",
    "features = [ptau217[ptau217_index]] + common\n",
    "select_df = load_bf2_df[features]\n",
    "select_df = select_df.dropna(how='any').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(select_df.shape[0]):\n",
    "    if select_df['fnc_ber_com_composite'][i] <= thres:\n",
    "        labels.append('0')\n",
    "    else:\n",
    "        labels.append('1')\n",
    "select_df['labels'] = labels\n",
    "select_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_idx = select_df['fnc_ber_com_composite']<thres\n",
    "pos_idx = (1-neg_idx).astype('bool')\n",
    "neg_df = select_df[neg_idx]\n",
    "pos_df = select_df[pos_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_tv_df, neg_test_df = train_test_split(neg_df, test_size=0.2, random_state=random_state)\n",
    "pos_tv_df, pos_test_df = train_test_split(pos_df, test_size=0.2, random_state=random_state)\n",
    "tv_df = pd.concat([neg_tv_df, pos_tv_df])\n",
    "test_df = pd.concat([neg_test_df, pos_test_df])\n",
    "\n",
    "tv_df = tv_df.drop(cd_drop,axis=1)\n",
    "test_df = test_df.drop(cd_drop,axis=1)\n",
    "\n",
    "X_train = tv_df.drop(['labels','fnc_ber_com_composite'], axis=1)\n",
    "y_train = tv_df['labels']\n",
    "X_test = test_df.drop(['labels','fnc_ber_com_composite'], axis=1)\n",
    "y_test = test_df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cls == 'extratree':\n",
    "    model = ExtraTreesClassifier()\n",
    "elif cls == 'gradientboost':\n",
    "    model = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bayes:\n",
    "    opt = bayescv(X_train, y_train, n_iter, model, random_state, cls=cls)\n",
    "    best_param = dict(opt.best_params_)\n",
    "else:\n",
    "    best_param = {'max_depth': 4,\n",
    " 'min_samples_leaf': 2,\n",
    " 'min_samples_split': 4,\n",
    " 'n_estimators': 500}\n",
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cls == 'extratree':\n",
    "    cls_model = ExtraTreesClassifier(**best_param, random_state=random_state)\n",
    "elif cls == 'gradientboost':\n",
    "    cls_model = GradientBoostingClassifier(**best_param, random_state=random_state)\n",
    "cls_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(cls_scores(cls_model, X_train, y_train, X_test, y_test), index=['Train_Acc', 'Test_Acc', 'Train_MacroF1', 'Test_MacroF1']).T\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_estimator(cls_model, X_test, y_test)\n",
    "plt.title('ROC of Classification between Amyloid Negative and Positive')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='white')\n",
    "cm = confusion_matrix(y_test, cls_model.predict(X_test), labels=cls_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=cls_model.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(cls_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_imp = pd.DataFrame(columns=['AVG_Importance'], index=[i for i in X_train.columns])\n",
    "fea_imp['AVG_Importance'] = cls_model.feature_importances_\n",
    "fea_imp = fea_imp.sort_values(by=\"AVG_Importance\" , inplace=False, ascending=True) \n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fea_imp.iloc[:,:].plot(kind='barh', color=['b'],figsize=(10,6))\n",
    "# bar_datalabel(ax)\n",
    "ax.set_xlabel('Weight')\n",
    "ax.set_xlim(0, np.max(fea_imp['AVG_Importance'].values)*1.1) # expand xlim to make labels easier to read\n",
    "plt.title('Feature Importance of the Classifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_fea_df = pd.DataFrame(fea_imp).rename(columns={'AVG_Importance':'Classification'})\n",
    "cls_fea_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdi_importances = pd.Series(cls_model.feature_importances_, index=X_train.columns)\n",
    "tree_importance_sorted_idx = np.argsort(cls_model.feature_importances_)\n",
    "tree_indices = np.arange(0, len(cls_model.feature_importances_)) + 0.5\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
    "mdi_importances.sort_values().plot.barh(ax=ax1)\n",
    "ax1.set_xlabel(\"Gini importance\")\n",
    "plot_permutation_importance(cls_model, X_train, y_train, ax2, random_state)\n",
    "ax2.set_xlabel(\"Decrease in accuracy score\")\n",
    "fig.suptitle(\n",
    "    \"Impurity-based vs. permutation importances on multicollinear features (train set)\"\n",
    ")\n",
    "_ = fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_df = select_df.drop(cd_drop,axis=1).reset_index(drop=True)\n",
    "X_shap = shap_df.drop(['labels','fnc_ber_com_composite'], axis=1)\n",
    "y_shap = shap_df['labels']\n",
    "y_pred_shap = cls_model.predict(X_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(cls_model)\n",
    "shap_values = explainer.shap_values(X_shap)\n",
    "shap_exp = explainer(X_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('SHAP Values on the Whole Dataset')\n",
    "shap.summary_plot(shap_values, X_shap, max_display=20, show=True, cmap='plasma', plot_size=[12,6], class_names=y_shap.unique())\n",
    "# savefig_name = crop[8:-7] + 'RF_SHAP_impact.png'\n",
    "# plt.savefig(savefig_name,format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cls == 'extratree':\n",
    "    model = ExtraTreesRegressor()\n",
    "elif cls == 'gradientboost':\n",
    "    model = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_idx = select_df['fnc_ber_com_composite']<=thres\n",
    "pos_idx = (1-neg_idx).astype('bool')\n",
    "neg_df = select_df[neg_idx]\n",
    "pos_df = select_df[pos_idx]\n",
    "\n",
    "tv_df, test_df = train_test_split(neg_df, test_size=0.2, random_state=random_state)\n",
    "\n",
    "tv_df = tv_df.drop(cd_drop,axis=1)\n",
    "test_df = test_df.drop(cd_drop,axis=1)\n",
    "\n",
    "X_train = tv_df.drop(['labels', 'fnc_ber_com_composite'], axis=1)\n",
    "y_train = tv_df['fnc_ber_com_composite']\n",
    "\n",
    "X_test = test_df.drop(['labels', 'fnc_ber_com_composite'], axis=1)\n",
    "y_test = test_df['fnc_ber_com_composite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    opt = bayescv(X_train, y_train, n_iter, model, random_state, cls=cls)\n",
    "    best_param = dict(opt.best_params_)\n",
    "else:\n",
    "    best_param = {\n",
    "    'max_depth': 3,\n",
    "    'min_samples_leaf': 2,\n",
    "    'min_samples_split': 2,\n",
    "    'n_estimators': 60}\n",
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cls == 'extratree':\n",
    "    neg_model = ExtraTreesRegressor(**best_param, random_state=random_state)\n",
    "elif cls == 'gradientboost':\n",
    "    neg_model = GradientBoostingRegressor(**best_param, random_state=random_state)\n",
    "neg_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(reg_scores(neg_model, X_train, y_train, X_test, y_test), index=['Train_R2', 'Test_R2', 'Train_MAPE', 'Test_MAPE']).T\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Observation vs. Prediction\n",
    "sns.set_theme(style='whitegrid', palette=sns.color_palette('deep'))\n",
    "y_pred = neg_model.predict(X_test)\n",
    "fig, ax = plt.subplots(1,1,figsize=(7,5))\n",
    "max_value = max(y_test.max(), y_pred.max(), y_train.max(), neg_model.predict(X_train).max())\n",
    "min_value = min(y_test.min(), y_pred.min(), y_train.min(), neg_model.predict(X_train).min())\n",
    "\n",
    "sns.scatterplot(x=y_train, y=neg_model.predict(X_train),  ax=ax, color=sns.color_palette('deep')[0])\n",
    "sns.scatterplot(x=y_test, y=y_pred,  ax=ax, marker='s', color=sns.color_palette('deep')[3])\n",
    "sns.regplot(x=y_train, y=neg_model.predict(X_train),  ax=ax, line_kws={'color':'darkblue'}, color=sns.color_palette('deep')[0],scatter=False)\n",
    "sns.regplot(x=y_test, y=y_pred, ax=ax, line_kws={'color':'darkred'}, color=sns.color_palette('deep')[3],scatter=False)\n",
    "l = min(y_train.min(), neg_model.predict(X_train).min()),max(y_train.max(), neg_model.predict(X_train).max())\n",
    "ax.plot(l,l,'--',c='black', linewidth=0.8)\n",
    "ax.set_title('Observation vs. Prediction within the Amyloid Negative Group')\n",
    "ax.set_xlabel('Observation [SUVR]')\n",
    "ax.set_ylabel('Prediction [SUVR]')\n",
    "ax.annotate(\"Train R2={:.3f}\".format(result_df['Train_R2'][0]), (0.98, 0.815))\n",
    "ax.annotate(\"Test R2={:.3f}\".format(result_df['Test_R2'][0]), (0.98, 0.8))\n",
    "ax.legend(['Train', 'Test'], loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid', palette=sns.color_palette(\"tab10\")[0:])\n",
    "fea_imp = pd.DataFrame(columns=['AVG_Importance'], index=[i for i in X_train.columns])\n",
    "fea_imp['AVG_Importance'] = neg_model.feature_importances_\n",
    "fea_imp = fea_imp.sort_values(by=\"AVG_Importance\" , inplace=False, ascending=True) \n",
    "\n",
    "row_names = {'PL_pT217T217percentmean_WashU_2023':'Plasma %p-tau217',\n",
    "             'CSF_Ab42_Ab40_ratio_imputed_Elecsys_2020_2022':'CSF AB42/AB40',\n",
    "             'age':'Age',\n",
    "             'apoe_genotype_baseline_variable':'APOE'}\n",
    "fea_imp = fea_imp.rename(index = row_names)\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fea_imp.iloc[:,:].plot(kind='barh',figsize=(10,6))\n",
    "# bar_datalabel(ax)\n",
    "ax.set_xlabel('Weight')\n",
    "ax.set_xlim(0, np.max(fea_imp['AVG_Importance'].values)*1.1) # expand xlim to make labels easier to read\n",
    "plt.title('Feature Importance within the Amyloid Negative Group')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_df, test_df = train_test_split(pos_df, test_size=0.2, random_state=random_state)\n",
    "\n",
    "if zscore:\n",
    "    zs_feature = ptau217[ptau217_index]\n",
    "    control_df = tv_df[((tv_df['Cognitive status'] == 'Normal') | \n",
    "                        (tv_df['Cognitive status'] == 'SCD')) & (tv_df['CSF Abnormal Ratio'] == 0)]\n",
    "    z_mean = control_df[zs_feature].mean()\n",
    "    z_std = control_df[zs_feature].std()\n",
    "    tv_df[zs_feature] = (tv_df[zs_feature]-z_mean)/z_std\n",
    "    test_df[zs_feature] = (test_df[zs_feature]-z_mean)/z_std\n",
    "    if ptau217_index in [0,1]:\n",
    "        bf1_df = load_bf1_df.drop('CSF Lilly p-tau217',axis=1)\n",
    "        bf1_df.rename(columns = {'Plasma Lilly p-tau217': select_df.columns[0]}, inplace = True)\n",
    "    elif ptau217_index in [2,3,4]:\n",
    "        bf1_df = load_bf1_df.drop('Plasma Lilly p-tau217',axis=1)\n",
    "        bf1_df.rename(columns = {'CSF Lilly p-tau217': select_df.columns[0]}, inplace = True)        \n",
    "    bf1_df = bf1_df.dropna(how='any')\n",
    "    bf1_df = bf1_df.drop(cd_drop,axis=1)\n",
    "    X_bf1 = bf1_df.drop(['fnc_ber_com_composite'], axis=1)\n",
    "    y_bf1 = bf1_df['fnc_ber_com_composite']\n",
    "\n",
    "tv_df = tv_df.drop(cd_drop,axis=1)\n",
    "test_df = test_df.drop(cd_drop,axis=1)\n",
    "\n",
    "X_train = tv_df.drop(['labels', 'fnc_ber_com_composite'], axis=1)\n",
    "y_train = tv_df['fnc_ber_com_composite']\n",
    "\n",
    "X_test = test_df.drop(['labels', 'fnc_ber_com_composite'], axis=1)\n",
    "y_test = test_df['fnc_ber_com_composite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 30\n",
    "cls = 'extratree'\n",
    "if cls == 'extratree':\n",
    "    model = ExtraTreesRegressor()\n",
    "elif cls == 'gradientboost':\n",
    "    model = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bayes:\n",
    "    opt = bayescv(X_train, y_train, n_iter, model, random_state=42, cls=cls)\n",
    "    best_param = dict(opt.best_params_)\n",
    "else:\n",
    "    best_param = {'max_depth': 6,\n",
    " 'min_samples_leaf': 1,\n",
    " 'min_samples_split': 5,\n",
    " 'n_estimators': 72}\n",
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cls == 'extratree':\n",
    "    pos_model = ExtraTreesRegressor(**best_param, random_state=random_state)\n",
    "elif cls == 'gradientboost':\n",
    "    pos_model = GradientBoostingRegressor(**best_param, random_state=random_state)\n",
    "pos_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rs=42, plasma\n",
    "result_df = pd.DataFrame(reg_scores(pos_model, X_train, y_train, X_test, y_test), index=['Train_R2', 'Test_R2', 'Train_MAPE', 'Test_MAPE']).T\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Observation vs. Prediction\n",
    "if zscore:\n",
    "    sns.set_theme(style='whitegrid', palette=sns.color_palette('deep'))\n",
    "    y_pred = pos_model.predict(X_test)\n",
    "    fig, ax = plt.subplots(1,1,figsize=(7,5))\n",
    "    max_value = max(y_test.max(), y_pred.max(), y_train.max(), pos_model.predict(X_train).max())\n",
    "    min_value = min(y_test.min(), y_pred.min(), y_train.min(), pos_model.predict(X_train).min())\n",
    "\n",
    "    sns.scatterplot(x=y_train, y=pos_model.predict(X_train),  ax=ax, color=sns.color_palette('deep')[0])\n",
    "    sns.scatterplot(x=y_test, y=y_pred,  ax=ax, marker='s', color=sns.color_palette('deep')[3])\n",
    "    sns.scatterplot(x=y_bf1, y=pos_model.predict(X_bf1),  ax=ax, marker='*', color=sns.color_palette('deep')[2])\n",
    "    sns.regplot(x=y_train, y=pos_model.predict(X_train),  ax=ax, line_kws={'color':'darkblue'}, color=sns.color_palette('deep')[0], scatter=False)\n",
    "    sns.regplot(x=y_test, y=y_pred, ax=ax, line_kws={'color':'darkred'}, color=sns.color_palette('deep')[3], scatter=False)\n",
    "    sns.regplot(x=y_bf1, y=pos_model.predict(X_bf1), ax=ax, line_kws={'color':'darkgreen'}, color=sns.color_palette('deep')[3], scatter=False)\n",
    "    l = min(y_train.min(), pos_model.predict(X_train).min()),max(y_train.max(), pos_model.predict(X_train).max())\n",
    "    ax.plot(l,l,'--',c='black', linewidth=0.8)\n",
    "    ax.set_xlabel('Observation')\n",
    "    ax.set_ylabel('Prediction')\n",
    "    ax.annotate(\"Train R2={:.3f}\".format(result_df['Train_R2'][0]), (2.0, 1.18))\n",
    "    ax.annotate(\"Test R2={:.3f}\".format(result_df['Test_R2'][0]), (2.0, 1.1))\n",
    "    ax.annotate(\"BF1 R2={:.3f}\".format(pos_model.score(X_bf1, y_bf1)), (2.0, 1.02))\n",
    "    ax.legend(['Train', 'Test', 'BF1'], loc='upper right')\n",
    "    ax.set_title('Observation vs. Prediction within the Amyloid Positive Group')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Observation vs. Prediction\n",
    "if not zscore:\n",
    "    sns.set_theme(style='whitegrid', palette=sns.color_palette('deep'))\n",
    "    y_pred = pos_model.predict(X_test)\n",
    "    fig, ax = plt.subplots(1,1,figsize=(7,5))\n",
    "    max_value = max(y_test.max(), y_pred.max(), y_train.max(), pos_model.predict(X_train).max())\n",
    "    min_value = min(y_test.min(), y_pred.min(), y_train.min(), pos_model.predict(X_train).min())\n",
    "\n",
    "    sns.scatterplot(x=y_train, y=pos_model.predict(X_train),  ax=ax, color=sns.color_palette('deep')[0])\n",
    "    sns.scatterplot(x=y_test, y=y_pred,  ax=ax, marker='s', color=sns.color_palette('deep')[3])\n",
    "    sns.regplot(x=y_train, y=pos_model.predict(X_train),  ax=ax, line_kws={'color':'darkblue'}, color=sns.color_palette('deep')[0], scatter=False)\n",
    "    sns.regplot(x=y_test, y=y_pred, ax=ax, line_kws={'color':'darkred'}, color=sns.color_palette('deep')[3], scatter=False)\n",
    "    l = min(y_train.min(), pos_model.predict(X_train).min()),max(y_train.max(), pos_model.predict(X_train).max())\n",
    "    ax.plot(l,l,'--',c='black', linewidth=0.8)\n",
    "    ax.set_xlabel('Observation [SUVR]')\n",
    "    ax.set_ylabel('Prediction [SUVR]')\n",
    "    ax.annotate(\"Train R2={:.3f}\".format(result_df['Train_R2'][0]), (2.0, 1.1))\n",
    "    ax.annotate(\"Test R2={:.3f}\".format(result_df['Test_R2'][0]), (2.0, 1.02))\n",
    "    ax.legend(['Train', 'Test'], loc='upper right')\n",
    "    ax.set_title('Observation vs. Prediction within the Amyloid Positive Group')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid', palette=sns.color_palette(\"tab10\")[3:])\n",
    "fea_imp = pd.DataFrame(columns=['AVG_Importance'], index=[i for i in X_train.columns])\n",
    "fea_imp['AVG_Importance'] = pos_model.feature_importances_\n",
    "fea_imp = fea_imp.sort_values(by=\"AVG_Importance\" , inplace=False, ascending=True) \n",
    "\n",
    "row_names = {'PL_pT217T217percentmean_WashU_2023':'Plasma %p-tau217',\n",
    "             'CSF_Ab42_Ab40_ratio_imputed_Elecsys_2020_2022':'CSF AB42/AB40',\n",
    "             'age':'Age',\n",
    "             'apoe_genotype_baseline_variable':'APOE'}\n",
    "fea_imp = fea_imp.rename(index = row_names)\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fea_imp.iloc[:,:].plot(kind='barh',figsize=(10,6))\n",
    "# bar_datalabel(ax)\n",
    "ax.set_xlabel('Weight')\n",
    "ax.set_xlim(0, np.max(fea_imp['AVG_Importance'].values)*1.1) # expand xlim to make labels easier to read\n",
    "plt.title('Feature Importance within the Amyloid Positive Group')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_fea_df = pd.DataFrame(fea_imp).rename(columns={'AVG_Importance':'Regression within Aβ-positive'})\n",
    "pos_fea_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([cls_fea_df.T, pos_fea_df.T])\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid', palette=sns.color_palette(\"tab10\")[3:])\n",
    "fig, ax = plt.subplots(1,1,figsize=(7,5))\n",
    "combined.plot.barh(rot=0, stacked=False, ax=ax, width=.3)\n",
    "plt.legend(['Plasma %P-tau217', 'CSF Aβ42/Aβ40'], loc='upper right')\n",
    "plt.xlabel('Weight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_df = pos_df.drop(cd_drop,axis=1).sort_values(by = 'fnc_ber_com_composite').reset_index(drop=True)\n",
    "X_shap = shap_df.drop(['labels', 'fnc_ber_com_composite'], axis=1)\n",
    "y_shap = shap_df['fnc_ber_com_composite']\n",
    "y_pred_shap = pos_model.predict(X_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(pos_model)\n",
    "shap_values = explainer.shap_values(X_shap)\n",
    "plt.title('SHAP_values on the Test Set')\n",
    "shap.summary_plot(shap_values, X_shap, max_display=10, show=True)\n",
    "plt.gcf().set_size_inches(10,8)\n",
    "# savefig_name = crop[8:-7] + 'RF_SHAP_impact.png'\n",
    "# plt.savefig(savefig_name,format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_exp = explainer(X_shap)\n",
    "output_df = pd.DataFrame()\n",
    "for idx in range(len(X_shap)):\n",
    "    details = pd.DataFrame({\n",
    "        'row_id':idx,\n",
    "        'feature': X_shap.columns,\n",
    "        'feature_value': X_shap.iloc[idx,:].values,\n",
    "        'base_value': shap_exp[idx].base_values,\n",
    "        'shap_values': shap_exp[idx].values,\n",
    "        'prediction': y_pred_shap[idx],\n",
    "        'observation': y_shap[idx],\n",
    "    })\n",
    "    output_df = pd.concat([output_df, details])\n",
    "\n",
    "impact = []\n",
    "for i in range(len(shap_df)):\n",
    "    v = np.abs(output_df[output_df['row_id'] == i]['shap_values'])\n",
    "    imp = list(v/np.sum(v))\n",
    "    impact = impact + imp\n",
    "    \n",
    "output_df['shap_impacts'] = impact\n",
    "\n",
    "shap_impacts = []\n",
    "shap_values_plot = []\n",
    "for chosen_feature in range(len(X_shap.columns)):\n",
    "    shap_impacts.append(output_df[output_df['feature']==X_shap.columns[chosen_feature]].reset_index(drop=True)['shap_impacts'])\n",
    "    shap_values_plot.append(output_df[output_df['feature']==X_shap.columns[chosen_feature]].reset_index(drop=True)['shap_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(10,7))\n",
    "i = 0\n",
    "for impacts in shap_impacts:\n",
    "    sns.scatterplot(x=y_shap, y=impacts)\n",
    "    sns.regplot(x=y_shap, y=impacts, order=1, scatter=False, ci=95, ax=ax, label=X_shap.columns[i])\n",
    "    i += 1\n",
    "plt.title('Feature Contribution at Different Amyloid PET SUVR')\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_xlabel('Amyloid PET SUVR')\n",
    "ax.set_ylabel('Contribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
