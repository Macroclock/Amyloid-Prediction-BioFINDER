{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.utils import resample\n",
    "from utils import bayescv, cv_scores, reg_all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',1000)\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "sns.set_theme(style='whitegrid')\n",
    "model_types = ['extratree', 'gradientboost']\n",
    "cls = model_types[0]\n",
    "thres = 1.03\n",
    "random_state = 42\n",
    "n_iter = 30\n",
    "\n",
    "zscore = False\n",
    "bayes = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BF2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_bf2_df = pd.read_csv('csv/BF2_R.csv')\n",
    "load_bf2_df['APOE'].replace({22.: '22', 23.: '23', 24.: '24', 33.: '33', 34.: '34', 44.: '44'}, inplace=True)\n",
    "if zscore:\n",
    "    load_bf1_df = pd.read_csv('csv/BF1_R_Z.csv')\n",
    "    load_bf1_df['APOE'].replace({22.: '22', 23.: '23', 24.: '24', 33.: '33', 34.: '34', 44.: '44'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptau217 = ['Plasma WashU %P-tau217',\n",
    "           'Plasma Lilly P-tau217',\n",
    "           'CSF Lilly P-tau217',\n",
    "           'CSF WashU P-tau217']\n",
    "\n",
    "common = ['CSF Aβ42/Aβ40',\n",
    "          'Age',\n",
    "          'APOE',\n",
    "          'ADAS',\n",
    "          'Education',\n",
    "          'Sex',\n",
    "          'Cognitive status',\n",
    "          'MMSE',\n",
    "          'CSF Abnormal Ratio',\n",
    "          'Diagnosis status',\n",
    "          'fnc_ber_com_composite']\n",
    "\n",
    "cd_drop = [ \n",
    "    # 'CSF Aβ42/Aβ40',\n",
    "                'ADAS',\n",
    "                'Education',\n",
    "                'Sex',\n",
    "                'Cognitive status',\n",
    "                'MMSE',\n",
    "                'CSF Abnormal Ratio',\n",
    "                'Diagnosis status']\n",
    "\n",
    "name = ['BF2-P-MS','BF2-P-IA','BF2-C-IA','BF2-C-MS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptau217_index = 0\n",
    "features = [ptau217[ptau217_index]] + common\n",
    "select_df = load_bf2_df[features]\n",
    "select_df = select_df.dropna(how='any').reset_index(drop=True)\n",
    "select_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_idx = select_df['fnc_ber_com_composite']<=thres\n",
    "pos_idx = (1-neg_idx).astype('bool')\n",
    "neg_df = select_df[neg_idx]\n",
    "pos_df = select_df[pos_idx]\n",
    "neg_tv_df, neg_test_df = train_test_split(neg_df, test_size=0.2, random_state=random_state)\n",
    "pos_tv_df, pos_test_df = train_test_split(pos_df, test_size=0.2, random_state=random_state)\n",
    "tv_df = pd.concat([neg_tv_df, pos_tv_df])\n",
    "test_df = pd.concat([neg_test_df, pos_test_df])\n",
    "\n",
    "if zscore:\n",
    "    zs_feature = ptau217[ptau217_index]\n",
    "    control_df = tv_df[((tv_df['Cognitive status'] == 'Normal') | \n",
    "                        (tv_df['Cognitive status'] == 'SCD')) & (tv_df['CSF Abnormal Ratio'] == 0)]\n",
    "    z_mean = control_df[zs_feature].mean()\n",
    "    z_std = control_df[zs_feature].std()\n",
    "    tv_df[zs_feature] = (tv_df[zs_feature]-z_mean)/z_std\n",
    "    test_df[zs_feature] = (test_df[zs_feature]-z_mean)/z_std\n",
    "    if ptau217_index in [0,1]:\n",
    "        bf1_df = load_bf1_df.drop('CSF Lilly P-tau217',axis=1)\n",
    "        bf1_df.rename(columns = {'Plasma Lilly P-tau217': select_df.columns[0]}, inplace = True)\n",
    "    elif ptau217_index in [2,3]:\n",
    "        bf1_df = load_bf1_df.drop('Plasma Lilly P-tau217',axis=1)\n",
    "        bf1_df.rename(columns = {'CSF Lilly P-tau217': select_df.columns[0]}, inplace = True)        \n",
    "    bf1_df = bf1_df.dropna(how='any')\n",
    "    bf1_df = bf1_df.drop(cd_drop,axis=1)\n",
    "    X_bf1 = bf1_df.drop(['fnc_ber_com_composite'], axis=1)\n",
    "    y_bf1 = bf1_df['fnc_ber_com_composite']\n",
    "\n",
    "tv_df = tv_df.drop(cd_drop,axis=1)\n",
    "test_df = test_df.drop(cd_drop,axis=1)\n",
    "X_train = tv_df.drop(['fnc_ber_com_composite'], axis=1)\n",
    "y_train = tv_df['fnc_ber_com_composite']\n",
    "\n",
    "X_test = test_df.drop(['fnc_ber_com_composite'], axis=1)\n",
    "y_test = test_df['fnc_ber_com_composite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if zscore:\n",
    "    bf1_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cls == 'extratree':\n",
    "    model = ExtraTreesRegressor()\n",
    "elif cls == 'gradientboost':\n",
    "    model = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BayesSearchCV or load best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bayes:\n",
    "    opt = bayescv(X_train, y_train, n_iter, model, random_state=random_state, cls=cls)\n",
    "    best_param = dict(opt.best_params_)\n",
    "    print(best_param)\n",
    "else:\n",
    "    if cls == 'extratree':\n",
    "        if ptau217_index == 0:\n",
    "            best_param = {'max_depth': 5,'min_samples_leaf': 1,'min_samples_split': 3,'n_estimators': 150}\n",
    "        if ptau217_index == 1:\n",
    "            best_param = {'max_depth': 6,'min_samples_leaf': 4,'min_samples_split': 2,'n_estimators': 50}\n",
    "        if ptau217_index == 2:\n",
    "            best_param = {'max_depth': 6,'min_samples_leaf': 4,'min_samples_split': 2,'n_estimators': 100}\n",
    "        if ptau217_index == 3:\n",
    "            best_param = {'max_depth': 12,'min_samples_leaf': 4,'min_samples_split': 2,'n_estimators': 64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_df = cv_scores(tv_df, 5, cls, best_param, thres, random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Optimal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tv_df.drop(['fnc_ber_com_composite'], axis=1)\n",
    "y_train = tv_df['fnc_ber_com_composite']\n",
    "\n",
    "X_test = test_df.drop(['fnc_ber_com_composite'], axis=1)\n",
    "y_test = test_df['fnc_ber_com_composite']\n",
    "if cls == 'extratree':\n",
    "    best_model = ExtraTreesRegressor(**best_param, random_state=random_state)\n",
    "elif cls == 'gradientboost':\n",
    "    best_model = GradientBoostingRegressor(**best_param, random_state=random_state)\n",
    "best_model.fit(X_train, y_train)\n",
    "## rs=42\n",
    "result_df = pd.DataFrame(reg_all_scores(best_model, X_train, y_train, X_test, y_test, thres), index=\n",
    "                         ['Train_R2', 'Test_R2', 'Test_R2_NEG', 'Test_R2_POS', 'Train_MAPE', 'Test_MAPE','Test_MAPE_NEG', 'Test_MAPE_POS']).T\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bootstrap of test\n",
    "bstp_scores = []\n",
    "bf1_scores = []\n",
    "for i in tqdm(range(100)):\n",
    "    X_testt, y_testt = resample(X_test, y_test, n_samples=80, replace=True, stratify=y_test, random_state=i)\n",
    "    bstp_scores.append([i] + list(reg_all_scores(best_model, X_train, y_train, X_testt, y_testt, thres)))\n",
    "    if zscore:\n",
    "        X_bf11, y_bf11 = resample(X_bf1, y_bf1, n_samples=80, replace=True, stratify=y_bf1, random_state=i)\n",
    "        bf1_scores.append([i] + list(reg_all_scores(best_model, X_train, y_train, X_bf11, y_bf11, thres))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bootstrap boxchart of BF2\n",
    "bstp_scores_df = pd.DataFrame(bstp_scores, columns=['iteration', 'Train_R2', 'Test_R2', 'Test_R2_NEG', 'Test_R2_POS', 'Train_MAPE', 'Test_MAPE','Test_MAPE_NEG', 'Test_MAPE_POS'])\n",
    "bstp_scores_df['data'] = 'BF2'\n",
    "sns.set_theme(style=\"whitegrid\", palette=sns.color_palette(\"tab10\"), font_scale=0.95)\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(8,5), gridspec_kw={'width_ratios': [1,3]})\n",
    "\n",
    "a_df = bstp_scores_df[['Test_R2']]\n",
    "a_df = a_df.set_axis(['Aβ'],axis='columns')\n",
    "sns.boxplot(a_df,width=0.5,whis=10,linewidth = 1.5,ax=ax[0])\n",
    "ax[0].set_yticks([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1])\n",
    "ax[0].set_ylabel('R squared')\n",
    "\n",
    "sns.set_theme(style=\"white\", palette=sns.color_palette(\"tab10\")[1:])\n",
    "\n",
    "b_df = bstp_scores_df[['Test_MAPE','Test_MAPE_NEG','Test_MAPE_POS']]\n",
    "b_df = b_df.set_axis(['Aβ','Aβ-','Aβ+'],axis='columns')\n",
    "sns.boxplot(b_df,width=0.5,whis=30,linewidth = 1.5,ax=ax[1])\n",
    "ax[1].set_yticks([0,0.02,0.04,0.06,0.08,0.10,0.12,0.14,0.16])\n",
    "ax[1].set_ylabel('MAPE')\n",
    "# ax[1].yaxis.tick_right()\n",
    "ax[1].yaxis.set_label_position(\"left\")\n",
    "ax[0].tick_params(direction=\"in\",  length=0)\n",
    "ax[1].tick_params(direction=\"in\", length=0)\n",
    "plt.suptitle('Model Performance on Evaluation Metrics ({0})'.format(name[ptau217_index]), y=0.95, fontsize=13)\n",
    "plt.ylim()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bootstrap boxchart of BF2 and BF1\n",
    "if zscore:\n",
    "    bf1_scores_df = pd.DataFrame(bf1_scores, columns=['iteration', 'Train_R2', 'Test_R2', 'Test_R2_NEG', 'Test_R2_POS', 'Train_MAPE', 'Test_MAPE','Test_MAPE_NEG', 'Test_MAPE_POS'])\n",
    "    bf1_scores_df['data'] = 'BF1'\n",
    "    sns.set_theme(style=\"whitegrid\", palette=sns.color_palette(\"tab10\"), font_scale=0.95)\n",
    "    fig, ax = plt.subplots(1,2,figsize=(10,6), gridspec_kw={'width_ratios': [1,3]})\n",
    "\n",
    "    tbf2_df = bstp_scores_df.dropna(how='any')\n",
    "    t1_df = pd.DataFrame(list(tbf2_df['Test_R2']),columns=['values'])\n",
    "    t1_df['metrics'] = 'Aβ'\n",
    "    t2_df = pd.DataFrame(list(tbf2_df['Test_MAPE']), columns=['values'])\n",
    "    t2_df['metrics'] = 'Aβ'\n",
    "    t3_df = pd.DataFrame(list(tbf2_df['Test_MAPE_NEG']), columns=['values'])\n",
    "    t3_df['metrics'] = 'Aβ-'\n",
    "    t4_df = pd.DataFrame(list(tbf2_df['Test_MAPE_POS']), columns=['values'])\n",
    "    t4_df['metrics'] = 'Aβ+'\n",
    "    r2bf2_df = t1_df.dropna(how='any')\n",
    "    vbf2_df = pd.concat([t2_df,t3_df,t4_df],axis=0).reset_index(drop=True)\n",
    "\n",
    "    tbf1_df = bf1_scores_df.dropna(how='any')\n",
    "    t1_df = pd.DataFrame(list(tbf1_df['Test_R2']),columns=['values'])\n",
    "    t1_df['metrics'] = 'Aβ'\n",
    "    t2_df = pd.DataFrame(list(tbf1_df['Test_MAPE']), columns=['values'])\n",
    "    t2_df['metrics'] = 'Aβ'\n",
    "    t3_df = pd.DataFrame(list(tbf1_df['Test_MAPE_NEG']), columns=['values'])\n",
    "    t3_df['metrics'] = 'Aβ-'\n",
    "    t4_df = pd.DataFrame(list(tbf1_df['Test_MAPE_POS']), columns=['values'])\n",
    "    t4_df['metrics'] = 'Aβ+'\n",
    "    r2bf1_df = t1_df.dropna(how='any')\n",
    "    vbf1_df = pd.concat([t2_df,t3_df,t4_df],axis=0).reset_index(drop=True)\n",
    "    vbf2_df['data'] = 'BF2'\n",
    "    vbf1_df['data'] = 'BF1'\n",
    "    r2bf2_df['data'] = 'BF2'\n",
    "    r2bf1_df['data'] = 'BF1'\n",
    "    r2bf_df = pd.concat([r2bf2_df,r2bf1_df]).reset_index(drop=True)\n",
    "    vbf_df = pd.concat([vbf2_df,vbf1_df]).reset_index(drop=True)\n",
    "    sns.boxplot(r2bf_df, x='metrics', y='values', width=0.6, hue=r2bf_df['data'], whis=30,linewidth = 1.5, palette=[sns.color_palette(\"tab10\", 8)[0],sns.color_palette(\"tab10\", 8)[3]],ax=ax[0])\n",
    "    sns.boxplot(vbf_df, x='metrics', y='values', width=0.6, hue=vbf_df['data'], whis=30,linewidth = 1.5, palette=[sns.color_palette(\"tab10\", 8)[0],sns.color_palette(\"tab10\", 8)[3]],ax=ax[1])\n",
    "    ax[0].set_yticks([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1])\n",
    "    ax[1].set_yticks([0,0.02,0.04,0.06,0.08,0.10,0.12,0.14,0.16,0.18])\n",
    "    ax[0].set_ylabel('R squared')\n",
    "    ax[1].set_ylabel('MAPE')\n",
    "    ax[0].set_xlabel('')\n",
    "    ax[1].set_xlabel('')\n",
    "    # ax[0].legend(loc='upper right')\n",
    "    plt.suptitle('Model Performance on Evaluation Metrics ({0} with Z-Score)'.format(name[ptau217_index]), y=0.95)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbf2_df.groupby('metrics').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbf1_df.groupby('metrics').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Observation vs. Prediction\n",
    "sns.set_theme(style='whitegrid', palette=sns.color_palette('deep'))\n",
    "y_pred = best_model.predict(X_test)\n",
    "fig, ax = plt.subplots(1,2,figsize=(14,5))\n",
    "max_value = max(y_test.max(), y_pred.max(), y_train.max(), best_model.predict(X_train).max())\n",
    "min_value = min(y_test.min(), y_pred.min(), y_train.min(), best_model.predict(X_train).min())\n",
    "sns.scatterplot(x=y_train, y=best_model.predict(X_train),  ax=ax[0], color=sns.color_palette('deep')[0])\n",
    "sns.scatterplot(x=y_test, y=y_pred,  ax=ax[0], marker='s', color=sns.color_palette('deep')[3])\n",
    "sns.regplot(x=y_train, y=best_model.predict(X_train),  ax=ax[0], line_kws={'color':'darkblue'}, scatter=False)\n",
    "sns.regplot(x=y_test, y=y_pred, ax=ax[0], line_kws={'color':'darkred'}, scatter=False)\n",
    "l = min(y_train.min(), best_model.predict(X_train).min()),max(y_train.max(), best_model.predict(X_train).max())\n",
    "ax[0].plot(l,l,'--',c='black', linewidth=0.8)\n",
    "ax[0].axvline(1.03, color = 'black', linewidth=1.5, linestyle='--')\n",
    "ax[0].text(1.05,2.2,'cutpoint=1.03',rotation=0)\n",
    "ax[0].set_title(\"Observation vs. Prediction\")\n",
    "ax[0].set_xlabel('Observation [SUVR]')\n",
    "ax[0].set_ylabel('Prediction [SUVR]')\n",
    "ax[0].annotate(\"Train R2={:.3f}\".format(result_df['Train_R2'][0]), (1.8, 0.9))\n",
    "ax[0].annotate(\"Test R2={:.3f}\".format(result_df['Test_R2'][0]), (1.8, 0.8))\n",
    "ax[0].legend(['Train', 'Test'], loc='upper right')\n",
    "## Observation vs. Residual\n",
    "sns.scatterplot(x=y_train, y=np.abs(best_model.predict(X_train)-y_train),  ax=ax[1], color=sns.color_palette('deep')[0])\n",
    "sns.scatterplot(x=y_test, y=np.abs(y_pred-y_test),  ax=ax[1], marker='s', color=sns.color_palette('deep')[3])\n",
    "sns.regplot(x=y_train, y=np.abs(best_model.predict(X_train)-y_train), order=3, ax=ax[1], line_kws={'color':'darkblue'}, scatter=False)\n",
    "sns.regplot(x=y_test, y=np.abs(y_pred-y_test), order=3, ax=ax[1], line_kws={'color':'darkred'}, scatter=False)\n",
    "ax[1].axvline(1.03, color = 'black', linewidth=1.5, linestyle='--')\n",
    "ax[1].text(1.05,0.85,'cutpoint=1.03',rotation=0)\n",
    "ax[1].set_xlabel('Observation [SUVR]')\n",
    "ax[1].set_ylabel('Residual [SUVR]')\n",
    "ax[1].set_title('Observation vs. Residual')\n",
    "ax[1].legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(14,5))\n",
    "sns.set_theme(style='whitegrid', palette=[sns.color_palette('deep')[3],sns.color_palette('deep')[0]])\n",
    "sns.histplot([best_model.predict(X_train), y_train], bins=100, alpha=0.8, ax=ax[0])\n",
    "sns.histplot([y_pred, y_test], bins=100, alpha=0.8, ax=ax[1])\n",
    "ax[0].legend(['Obs.','Pred.'])\n",
    "ax[1].legend(['Obs.','Pred.'])\n",
    "ax[0].set_title('Histogram of Amyloid SUVR on Training Set')\n",
    "ax[1].set_title('Histogram of Amyloid SUVR on Test Set')\n",
    "ax[0].axvline(1.03, color = 'black', linewidth=1.5, linestyle='--')\n",
    "ax[0].text(1.05,140,'cutpoint=1.03',rotation=0)\n",
    "ax[1].axvline(1.03, color = 'black', linewidth=1.5, linestyle='--')\n",
    "ax[1].text(1.05,36,'cutpoint=1.03',rotation=0)\n",
    "ax[0].set_xlabel('SUVR')\n",
    "ax[1].set_xlabel('SUVR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature importance from estimator\n",
    "sns.set_theme(style='whitegrid')\n",
    "fea_imp = pd.DataFrame(columns=['AVG_Importance'], index=[i for i in X_train.columns])\n",
    "fea_imp['AVG_Importance'] = best_model.feature_importances_\n",
    "fea_imp = fea_imp.sort_values(by=\"AVG_Importance\" , inplace=False, ascending=True) \n",
    "\n",
    "row_names = {'PL_pT217T217percentmean_WashU_2023':'Plasma %p-tau217',\n",
    "             'CSF_Ab42_Ab40_ratio_imputed_Elecsys_2020_2022':'CSF AB42/AB40',\n",
    "             'age':'Age',\n",
    "             'apoe_genotype_baseline_variable':'APOE'}\n",
    "fea_imp = fea_imp.rename(index = row_names)\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fea_imp.iloc[:,:].plot(kind='barh', color=['r'],figsize=(10,6))\n",
    "# bar_datalabel(ax)\n",
    "ax.set_xlabel('Weight')\n",
    "ax.set_xlim(0, np.max(fea_imp['AVG_Importance'].values)*1.1) # expand xlim to make labels easier to read\n",
    "plt.title('Feature Importance Derived from the Gradient Boosting Regressor', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP (Not for Z-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_df = select_df.drop(cd_drop,axis=1).sort_values(by = 'fnc_ber_com_composite').reset_index(drop=True)\n",
    "# shap_df = tv_df.sort_values(by = 'fnc_ber_com_composite').reset_index(drop=True)\n",
    "X_shap = shap_df.drop(['fnc_ber_com_composite'], axis=1)\n",
    "y_shap = shap_df['fnc_ber_com_composite']\n",
    "y_pred_shap = best_model.predict(X_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer.shap_values(X_shap)\n",
    "plt.title('SHAP values')\n",
    "shap.summary_plot(shap_values, X_shap, max_display=10, show=True, cmap='plasma')\n",
    "# savefig_name = crop[8:-7] + 'RF_SHAP_impact.png'\n",
    "# plt.savefig(savefig_name,format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_exp = explainer(X_shap)\n",
    "# output_df = pd.DataFrame()\n",
    "# for idx in range(len(X_shap)):\n",
    "#     details = pd.DataFrame({\n",
    "#         'row_id':idx,\n",
    "#         'feature': X_shap.columns,\n",
    "#         'feature_value': X_shap.iloc[idx,:].values,\n",
    "#         'base_value': shap_exp[idx].base_values,\n",
    "#         'shap_values': shap_exp[idx].values,\n",
    "#         'prediction': y_pred_shap[idx],\n",
    "#         'observation': y_shap[idx],\n",
    "#     })\n",
    "#     output_df = pd.concat([output_df, details])\n",
    "\n",
    "# impact = []\n",
    "# for i in range(len(shap_df)):\n",
    "#     v = np.abs(output_df[output_df['row_id'] == i]['shap_values'])\n",
    "#     imp = list(v/np.sum(v))\n",
    "#     impact = impact + imp\n",
    "    \n",
    "# output_df['shap_impacts'] = impact\n",
    "\n",
    "# shap_impacts = []\n",
    "# shap_values_plot = []\n",
    "# for chosen_feature in range(len(X_shap.columns)):\n",
    "#     shap_impacts.append(output_df[output_df['feature']==X_shap.columns[chosen_feature]].reset_index(drop=True)['shap_impacts'])\n",
    "#     shap_values_plot.append(output_df[output_df['feature']==X_shap.columns[chosen_feature]].reset_index(drop=True)['shap_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Feature contribution\n",
    "# sns.set_theme(style='white', palette=sns.color_palette('deep'))\n",
    "# fig, ax = plt.subplots(1,1,figsize=(10,7))\n",
    "# i = 0\n",
    "# for impacts in shap_impacts:\n",
    "#     sns.scatterplot(x=y_shap, y=impacts)\n",
    "#     sns.regplot(x=y_shap, y=impacts, order=2, scatter=False, ci=95, ax=ax, label=X_shap.columns[i])\n",
    "#     i += 1\n",
    "# plt.title('Feature Contribution at Different Amyloid PET SUVR')\n",
    "# ax.legend(loc='upper right')\n",
    "# ax.set_xlabel('Amyloid PET SUVR')\n",
    "# ax.set_ylabel('Contribution')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_pred_100_df = pd.DataFrame([y_shap.values,y_pred_shap]).T.rename(columns={0:'obs',1:'pre'})\n",
    "obs_pred_100_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=obs_pred_100_df['obs'],y=obs_pred_100_df['pre'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "py = []\n",
    "for i in range(6):\n",
    "    if i == 0:\n",
    "        x.append(obs_pred_100_df[(obs_pred_100_df['obs'] <=thres)]['pre'])\n",
    "        py.append(obs_pred_100_df[(obs_pred_100_df['obs'] <=thres)].shape[0])\n",
    "    elif i == 1:\n",
    "        x.append(obs_pred_100_df[(obs_pred_100_df['obs'] >thres) & (obs_pred_100_df['obs'] <=1.1)]['pre'])\n",
    "        py.append(obs_pred_100_df[(obs_pred_100_df['obs'] >thres) & (obs_pred_100_df['obs'] <=1.1)].shape[0])\n",
    "    elif i == 2:\n",
    "        x.append(obs_pred_100_df[(obs_pred_100_df['obs'] >1.1) & (obs_pred_100_df['obs'] <=1.25)]['pre'])\n",
    "        py.append(obs_pred_100_df[(obs_pred_100_df['obs'] >1.1) & (obs_pred_100_df['obs'] <=1.25)].shape[0]) \n",
    "    elif i == 3:\n",
    "        x.append(obs_pred_100_df[(obs_pred_100_df['obs'] >1.25) & (obs_pred_100_df['obs'] <=1.45)]['pre'])\n",
    "        py.append(obs_pred_100_df[(obs_pred_100_df['obs'] >1.25) & (obs_pred_100_df['obs'] <=1.45)].shape[0]) \n",
    "    elif i == 4:\n",
    "        x.append(obs_pred_100_df[(obs_pred_100_df['obs'] >1.45) & (obs_pred_100_df['obs'] <=1.7)]['pre'])\n",
    "        py.append(obs_pred_100_df[(obs_pred_100_df['obs'] >1.45) & (obs_pred_100_df['obs'] <=1.7)].shape[0]) \n",
    "    elif i == 5:\n",
    "        x.append(obs_pred_100_df[(obs_pred_100_df['obs'] >1.7) & (obs_pred_100_df['obs'] <=3.0)]['pre'])\n",
    "        py.append(obs_pred_100_df[(obs_pred_100_df['obs'] >1.7) & (obs_pred_100_df['obs'] <=3.0)].shape[0]) \n",
    "        break\n",
    "nr_groups = i+1\n",
    "print(np.sum(py)/920, nr_groups)\n",
    "py = py/np.sum(py)\n",
    "print(py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(10,6))\n",
    "for i in range(nr_groups):\n",
    "    sns.kdeplot(x[i],ax=ax)\n",
    "plt.legend(['obs<=1.03','1.03<obs<=1.1','1.1<obs<=1.25','1.25<obs<=1.45','1.45<obs<=1.7',\n",
    "            '1.7<obs','2.0<obs'], loc='upper right')\n",
    "plt.title('P(prediction|observation)')\n",
    "plt.xlabel('prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(10,6))\n",
    "for i in range(nr_groups):\n",
    "    sns.histplot(x[i],ax=ax, stat='probability', kde=True, kde_kws={'cut': 3})\n",
    "    ax.containers[0].remove()\n",
    "plt.legend(['obs<=1.03','1.03<obs<=1.1','1.1<obs<=1.3','1.3<obs<=1.5','1.5<obs<=1.7',\n",
    "            '1.7<obs<=2.0','2.0<obs'], loc='upper right')\n",
    "plt.title('P(prediction|observation)')\n",
    "plt.xlabel('prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, bx = plt.subplots(1,1,figsize=(10,6))\n",
    "sns.ecdfplot(obs_pred_100_df['obs'],ax=bx)\n",
    "plt.title('P(observation belongs to group x)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, cx= plt.subplots(1,1,figsize=(10,6))\n",
    "for i in range(nr_groups):\n",
    "    fit = ax.get_lines()[i].get_data() # Getting the data from the plotted line\n",
    "    xfit, yfit = fit[0], fit[1]*py[i]\n",
    "    cx.plot(xfit, yfit) \n",
    "plt.legend(['obs<=1.03','1.03<obs<=1.1','1.1<obs<=1.3','1.3<obs<=1.5','1.5<obs<=1.7',\n",
    "            '1.7<obs<=2.0','2.0<obs'], loc='upper right')\n",
    "plt.title('P(observation | prediction)')\n",
    "plt.ylim([0,0.062])\n",
    "plt.xlabel('prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_points = [0.9, 1.03, 1.15, 1.35, 1.55, 1.7]\n",
    "nr_cutpoints = 91\n",
    "cut_points = list(np.around(np.linspace(0.9,1.8,nr_cutpoints),2))\n",
    "l = len(cut_points)\n",
    "pyx = np.zeros([nr_groups,l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nr_groups):\n",
    "    fit = cx.get_lines()[i].get_data() # Getting the data from the plotted line\n",
    "    xfit, yfit = fit[0], fit[1]\n",
    "    for j in range(l):\n",
    "        index = np.abs(xfit-cut_points[j]).argmin()\n",
    "        pyx[i][j] = yfit[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px = np.sum(pyx,axis=0)\n",
    "prob = pyx/px\n",
    "prob_df = pd.DataFrame(prob, columns=cut_points)\n",
    "prob_df = prob_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxindex = []\n",
    "for i in range(prob_df.shape[0]):\n",
    "    maxindex.append(prob_df.iloc[i,:].argmax())\n",
    "maxindex = np.asarray(maxindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(40,15))\n",
    "ax = prob_df.plot(kind='bar', stacked=True, ax=ax, rot=0, width=1, alpha=0.85)\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "for bar in ax.patches:\n",
    "  if i < nr_cutpoints*1:\n",
    "    c = maxindex == 0\n",
    "    if c[j]:\n",
    "      bar.set_color((0.043, 0.471, 0.941))\n",
    "  elif i < nr_cutpoints*2:\n",
    "    c = maxindex == 1\n",
    "    if c[j-nr_cutpoints*1]:\n",
    "      bar.set_color((0.969, 0.565, 0.027))\n",
    "  elif i < nr_cutpoints*3:\n",
    "    c = maxindex == 2\n",
    "    if c[j-nr_cutpoints*2]:\n",
    "      bar.set_color('green')\n",
    "  elif i < nr_cutpoints*4:\n",
    "    c = maxindex == 3\n",
    "    if c[j-nr_cutpoints*3]:\n",
    "      bar.set_color((0.929, 0.078, 0.078))\n",
    "  elif i < nr_cutpoints*5:\n",
    "    c = maxindex == 4\n",
    "    if c[j-nr_cutpoints*4]:\n",
    "      bar.set_color((0.424, 0.059, 0.89))\n",
    "  elif i < nr_cutpoints*6:\n",
    "    c = maxindex == 5\n",
    "    if c[j-nr_cutpoints*5]:\n",
    "      bar.set_color((0.169, 0.125, 0.125))\n",
    "  j += 1\n",
    "  i += 1\n",
    "\n",
    "plt.legend(['obs<=1.03','1.03<obs<=1.1','1.1<obs<=1.25','1.25<obs<=1.45','1.45<obs<=1.7',\n",
    "            '1.7<obs',], loc='upper right')\n",
    "plt.xlabel('Predicted Amyloid SUVR')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('The probabilities of the predicted value located in different observation groups')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\", palette=sns.color_palette(\"deep\"))\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "X_axis = np.arange(l)\n",
    "for i in range(l):\n",
    "    plt.bar(X_axis - 0.4 + 0.1*i, prob_df[i], 0.1)\n",
    "    for index, value in enumerate(prob_df[i]):\n",
    "        if value>0.01:\n",
    "            plt.text(index- 0.45 + 0.1*i, value+0.01,\n",
    "                    str(float(\"{:.2f}\".format(value))))\n",
    "plt.legend(['obs<=1.03','1.03<obs<=1.1','1.1<obs<=1.25','1.25<obs<=1.45','1.45<obs<=1.7',\n",
    "            '1.7<obs',], loc='upper right')  \n",
    "plt.xticks(X_axis, prob_df.index)\n",
    "plt.xlabel('Predicted Amyloid SUVR')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Probabilities of Predicted Values Located in Different Observation Groups')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
